{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Évaluation du modèle avec le score BLEU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons donc testé 4 configurations différentes pour notre modèle :\n",
    "- Modèle 1 : Tokenisation et corpus du domaine\n",
    "- Modèle 2 : Tokenisation et corpus partiellement hors-domaine\n",
    "- Modèle 3 : Lemmatisation et corpus du domaine\n",
    "- Modèle 4 : Lemmatisation et corpus partiellement hors-domaine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant utiliser le score BLEU pour évaluer nos différents modèles et déterminer lequel est le plus performant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Ce script calcule le score BLEU d'une traduction par rapport à une référence en utilisant la bibliothèque sacrebleu.\n",
    "\n",
    "# Utilisation\n",
    "\n",
    "Ce script prend deux arguments en ligne de commande :\n",
    "1. Le chemin vers le fichier de référence (path_ref).\n",
    "2. Le chemin vers le fichier de traduction généré par OPENNMT (path_trad).\n",
    "\n",
    "Le script lit les deux fichiers, calcule le score BLEU entre la traduction et la référence, puis affiche ce score.\n",
    "\n",
    "# Exemple\n",
    "\n",
    "Pour exécuter ce script à partir de la ligne de commande :\n",
    "\n",
    "    python script.py chemin_vers_fichier_ref chemin_vers_fichier_trad\n",
    "\n",
    "# Arguments\n",
    "\n",
    "- path_ref : str\n",
    "    Chemin vers le fichier de référence. Ce fichier doit contenir le texte de référence, avec chaque phrase sur une ligne séparée.\n",
    "- path_trad : str\n",
    "    Chemin vers le fichier de traduction. Ce fichier doit contenir le texte traduit par OPENNMT, avec chaque phrase sur une ligne séparée.\n",
    "\n",
    "# Bibliothèques nécessaires\n",
    "\n",
    "- sys : Pour lire les arguments en ligne de commande.\n",
    "- sacrebleu : Pour calculer le score BLEU.\n",
    "\n",
    "# Sortie\n",
    "\n",
    "Le script affiche le score BLEU calculé pour la traduction par rapport à la référence.\n",
    "\"\"\"\n",
    "#__________MODULES\n",
    "\n",
    "import sys\n",
    "import sacrebleu\n",
    "\n",
    "#__________MAIN\n",
    "\n",
    "path_ref = sys.argv[1]  # Chemin vers le fichier de référence\n",
    "path_trad = sys.argv[2]  # Chemin vers le fichier issu de la traduction OPENNMT\n",
    "\n",
    "# Lire les fichiers\n",
    "with open(path_ref, 'r', encoding='utf-8') as ref:\n",
    "    references = [ref.read().strip().split('\\n')]\n",
    "\n",
    "with open(path_trad, 'r', encoding='utf-8') as trad:\n",
    "    traduction = trad.read().strip().split('\\n')\n",
    "\n",
    "# Calculer le score BLEU\n",
    "bleu = sacrebleu.corpus_bleu(traduction, references, force=True)\n",
    "print(bleu.score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle 1 : Tokenisation et corpus du domaine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le score BLEU pour le modèle 1 : Tokenisation et corpus du domaine est de :\n",
      "10.839912170150125\n"
     ]
    }
   ],
   "source": [
    "print(\"Le score BLEU pour le modèle 1 : Tokenisation et corpus du domaine est de :\")\n",
    "!python3 bleu.py ../data/clean/europarl/Europarl_test_500.tok.true.clean.fr ../data/outputs/Europarl_pred_500_run1.tok.true.clean.fr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle 2 : Tokenisation et corpus partiellement hors-domaine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le score BLEU pour le modèle 2 EUROPARL : Tokenisation et corpus partiellement hors-domaine est de :\n",
      "6.91370962781569\n"
     ]
    }
   ],
   "source": [
    "print(\"Le score BLEU pour le modèle 2 EUROPARL : Tokenisation et corpus partiellement hors-domaine est de :\")\n",
    "!python3 bleu.py ../data/clean/europarl/Europarl_test_500.tok.true.clean.fr ../data/outputs/Europarl_pred_500_run2.tok.true.clean.fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le score BLEU pour le modèle 2 EMEA : Tokenisation et corpus partiellement hors-domaine est de :\n",
      "3.5149778745449924\n"
     ]
    }
   ],
   "source": [
    "print(\"Le score BLEU pour le modèle 2 EMEA : Tokenisation et corpus partiellement hors-domaine est de :\")\n",
    "!python3 bleu.py ../data/clean/emea/Emea_test_50.tok.true.clean.fr ../data/outputs/Emea_pred_50_run2.tok.true.clean.fr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle 3 : Lemmatisation et corpus du domaine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le score BLEU pour le modèle 3 : Lemmatisation et corpus du domaine est de :\n",
      "3.9518926146627753\n"
     ]
    }
   ],
   "source": [
    "print(\"Le score BLEU pour le modèle 3 : Lemmatisation et corpus du domaine est de :\")\n",
    "!python3 bleu.py ../data/clean/europarl/Europarl_test_500.lem.true.clean.fr ../data/outputs/Europarl_pred_500_run3.lem.true.clean.fr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle 4 : Lemmatisation et corpus partiellement hors-domaine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le score BLEU pour le modèle 4 : Lemmatisation et corpus partiellement hors-domaine est de :\n",
      "2.618889161951621\n"
     ]
    }
   ],
   "source": [
    "print(\"Le score BLEU pour le modèle 4 : Lemmatisation et corpus partiellement hors-domaine est de :\")\n",
    "!python3 bleu.py ../data/clean/europarl/Europarl_test_500.lem.true.clean.fr ../data/outputs/Europarl_pred_500_run4.lem.true.clean.fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le score BLEU pour le modèle 4 EMEA : Lemmatisation et corpus partiellement hors-domaine est de :\n",
      "0.3981545434210293\n"
     ]
    }
   ],
   "source": [
    "print(\"Le score BLEU pour le modèle 4 EMEA : Lemmatisation et corpus partiellement hors-domaine est de :\")\n",
    "!python3 bleu.py ../data/clean/emea/Emea_test_50.lem.true.clean.fr ../data/outputs/Emea_pred_50_run4.lem.true.clean.fr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CondaTAA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
